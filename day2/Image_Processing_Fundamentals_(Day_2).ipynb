{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "plPW67Gx39nY",
        "F3ceXlnP4CP8",
        "kX9GEvFmDP-B",
        "qUaA1ZjyE4cx",
        "1_hisD29MAtD",
        "yAg_5fp4Q0sl"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Image Thresholding\n",
        "Learn to convert images to binary images using global thresholding, Adaptive thresholding, Otsu's binarization etc.\n"
      ],
      "metadata": {
        "id": "plPW67Gx39nY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Goal\n",
        "\n",
        "Learn **simple thresholding**, **adaptive thresholding**, and **Otsu's thresholding**.  \n",
        "You will learn the functions `cv.threshold` and `cv.adaptiveThreshold`.\n",
        "\n",
        "---\n",
        "\n",
        "## Simple Thresholding\n",
        "\n",
        "Here, the matter is straight-forward. For every pixel, the same threshold value is applied.  \n",
        "If the pixel value is smaller than or equal to the threshold, it is set to `0`, otherwise it is set to a **maximum value**.  \n",
        "\n",
        "The function `cv.threshold` is used to apply the thresholding.\n",
        "\n",
        "- The **first argument** is the source image, which should be a grayscale image.\n",
        "- The **second argument** is the threshold value which is used to classify the pixel values.\n",
        "- The **third argument** is the maximum value which is assigned to pixel values exceeding the threshold.\n",
        "- OpenCV provides **different types of thresholding** which is given by the **fourth parameter** of the function.\n",
        "\n",
        "Basic thresholding as described above is done by using the type `cv.THRESH_BINARY`.\n",
        "\n",
        "All simple thresholding types are:\n",
        "\n",
        "- `cv.THRESH_BINARY`\n",
        "- `cv.THRESH_BINARY_INV`\n",
        "- `cv.THRESH_TRUNC`\n",
        "- `cv.THRESH_TOZERO`\n",
        "- `cv.THRESH_TOZERO_INV`\n",
        "\n",
        "See the documentation of the types for the differences.\n",
        "\n",
        "The method returns **two outputs**:\n",
        "\n",
        "1. The threshold that was used.\n",
        "2. The thresholded image.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "ePriMjtcydH5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This code compares the different simple thresholding types:\n"
      ],
      "metadata": {
        "id": "x_CANWffzSSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "img = cv.imread('images/gradient.png', cv.IMREAD_GRAYSCALE)\n",
        "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
        "ret,thresh1 = cv.threshold(img,127,255,cv.THRESH_BINARY)\n",
        "ret,thresh2 = cv.threshold(img,127,255,cv.THRESH_BINARY_INV)\n",
        "ret,thresh3 = cv.threshold(img,127,255,cv.THRESH_TRUNC)\n",
        "ret,thresh4 = cv.threshold(img,127,255,cv.THRESH_TOZERO)\n",
        "ret,thresh5 = cv.threshold(img,127,255,cv.THRESH_TOZERO_INV)\n",
        "\n",
        "titles = ['Original Image','BINARY','BINARY_INV','TRUNC','TOZERO','TOZERO_INV']\n",
        "images = [img, thresh1, thresh2, thresh3, thresh4, thresh5]\n",
        "\n",
        "for i in range(6):\n",
        "    plt.subplot(2,3,i+1),plt.imshow(images[i],'gray',vmin=0,vmax=255)\n",
        "    plt.title(titles[i])\n",
        "    plt.xticks([]),plt.yticks([])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1epSAOLUzT0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adaptive Thresholding\n",
        "\n",
        "In the previous section, we used one **global value** as a threshold.  \n",
        "But this might not be good in all cases, e.g. if an image has different lighting conditions in different areas.  \n",
        "\n",
        "In that case, **adaptive thresholding** can help.  \n",
        "Here, the algorithm determines the threshold for a pixel based on a **small region around it**.  \n",
        "So we get different thresholds for different regions of the same image, which gives better results for images with **varying illumination**.\n",
        "\n",
        "In addition to the parameters described above, the method `cv.adaptiveThreshold` takes three input parameters:\n",
        "\n",
        "### `adaptiveMethod`\n",
        "\n",
        "This decides how the threshold value is calculated:\n",
        "\n",
        "- `cv.ADAPTIVE_THRESH_MEAN_C`:  \n",
        "  The threshold value is the **mean of the neighbourhood area** minus the constant `C`.\n",
        "\n",
        "- `cv.ADAPTIVE_THRESH_GAUSSIAN_C`:  \n",
        "  The threshold value is a **Gaussian-weighted sum of the neighbourhood values** minus the constant `C`.\n",
        "\n",
        "### `blockSize`\n",
        "\n",
        "Determines the **size of the neighbourhood area**.\n",
        "\n",
        "### `C`\n",
        "\n",
        "A constant that is **subtracted** from the mean or weighted sum of the neighbourhood pixels.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "kr-cW3nQ18yV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The code below compares **global thresholding** and **adaptive thresholding** for an image with varying illumination:"
      ],
      "metadata": {
        "id": "wOCqiA0-2UCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "img = cv.imread('images/sudoku.png', cv.IMREAD_GRAYSCALE)\n",
        "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
        "img = cv.medianBlur(img,5)\n",
        "\n",
        "ret,th1 = cv.threshold(img,127,255,cv.THRESH_BINARY)\n",
        "th2 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_MEAN_C,\\\n",
        "            cv.THRESH_BINARY,11,2)\n",
        "th3 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
        "            cv.THRESH_BINARY,11,2)\n",
        "\n",
        "titles = ['Original Image', 'Global Thresholding (v = 127)',\n",
        "            'Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']\n",
        "images = [img, th1, th2, th3]\n",
        "\n",
        "for i in range(4):\n",
        "    plt.subplot(2,2,i+1),plt.imshow(images[i],'gray')\n",
        "    plt.title(titles[i])\n",
        "    plt.xticks([]),plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TssQlvZL2WNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Otsu's Binarization\n",
        "\n",
        "In global thresholding, we used an **arbitrarily chosen value** as a threshold.  \n",
        "In contrast, **Otsu's method** avoids having to choose a value and determines it **automatically**.\n",
        "\n",
        "Consider an image with only **two distinct image values** (a **bimodal** image), where the histogram consists of two peaks.  \n",
        "A good threshold would be in the **middle of those two values**.  \n",
        "Similarly, **Otsu's method** determines an **optimal global threshold** value from the image histogram.\n",
        "\n",
        "To do this, the `cv.threshold()` function is used, where `cv.THRESH_OTSU` is passed as an **extra flag**.  \n",
        "The threshold value can be chosen arbitrarily.  \n",
        "The algorithm then **finds the optimal threshold value**, which is returned as the **first output**.\n",
        "\n",
        "---\n",
        "\n",
        "Check out the example below:\n",
        "\n",
        "- The **input image** is a **noisy image**.\n",
        "- In the **first case**, global thresholding with a value of 127 is applied.\n",
        "- In the **second case**, Otsu's thresholding is applied **directly**.\n",
        "- In the **third case**, the image is first filtered with a **5x5 Gaussian kernel** to remove the noise, then **Otsu thresholding** is applied.\n",
        "\n",
        "See how **noise filtering improves the result**.\n"
      ],
      "metadata": {
        "id": "lObStVQy23dc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "img = cv.imread('images/noisy2.png', cv.IMREAD_GRAYSCALE)\n",
        "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
        "\n",
        "# global thresholding\n",
        "ret1,th1 = cv.threshold(img,127,255,cv.THRESH_BINARY)\n",
        "\n",
        "# Otsu's thresholding\n",
        "ret2,th2 = cv.threshold(img,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
        "\n",
        "# Otsu's thresholding after Gaussian filtering\n",
        "blur = cv.GaussianBlur(img,(5,5),0)\n",
        "ret3,th3 = cv.threshold(blur,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
        "\n",
        "# plot all the images and their histograms\n",
        "images = [img, 0, th1,\n",
        "          img, 0, th2,\n",
        "          blur, 0, th3]\n",
        "titles = ['Original Noisy Image','Histogram','Global Thresholding (v=127)',\n",
        "          'Original Noisy Image','Histogram',\"Otsu's Thresholding\",\n",
        "          'Gaussian filtered Image','Histogram',\"Otsu's Thresholding\"]\n",
        "\n",
        "for i in range(3):\n",
        "    plt.subplot(3,3,i*3+1),plt.imshow(images[i*3],'gray')\n",
        "    plt.title(titles[i*3]), plt.xticks([]), plt.yticks([])\n",
        "    plt.subplot(3,3,i*3+2),plt.hist(images[i*3].ravel(),256)\n",
        "    plt.title(titles[i*3+1]), plt.xticks([]), plt.yticks([])\n",
        "    plt.subplot(3,3,i*3+3),plt.imshow(images[i*3+2],'gray')\n",
        "    plt.title(titles[i*3+2]), plt.xticks([]), plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ir5kvk8z3Ydd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Smoothing Images\n",
        "\n",
        "Learn to blur the images, filter the images with custom kernels etc.\n"
      ],
      "metadata": {
        "id": "F3ceXlnP4CP8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Goals\n",
        "\n",
        "Learn to:\n",
        "\n",
        "- Blur images with various **low pass filters**\n",
        "- Apply **custom-made filters** to images (2D convolution)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "wbg0tZ2J4Twd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2D Convolution (Image Filtering)\n",
        "\n",
        "As in one-dimensional signals, images can also be filtered with various types of filters like:\n",
        "\n",
        "- **Low-pass filters (LPF)**: Help in **removing noise**, **blurring images**, etc.\n",
        "- **High-pass filters (HPF)**: Help in **finding edges** in images.\n",
        "\n",
        "OpenCV provides a function `cv.filter2D()` to **convolve a kernel with an image**.\n",
        "\n",
        "As an example, we will try an **averaging filter** on an image.\n",
        "\n",
        "A **5Ã—5 averaging filter kernel** is defined as:\n",
        "\n",
        "\n",
        "$$\n",
        "K = \\frac{1}{25}\n",
        "\\begin{bmatrix}\n",
        "1 & 1 & 1 & 1 & 1 \\\\\n",
        "1 & 1 & 1 & 1 & 1 \\\\\n",
        "1 & 1 & 1 & 1 & 1 \\\\\n",
        "1 & 1 & 1 & 1 & 1 \\\\\n",
        "1 & 1 & 1 & 1 & 1\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "The operation works like this:\n",
        "\n",
        "- Place the **5Ã—5 kernel** centered over a pixel.\n",
        "- Add up the values of all **25 pixels** covered by the kernel.\n",
        "- Compute the **average** of these values.\n",
        "- Replace the **central pixel** with this average.\n",
        "\n",
        "This process is repeated across the entire image.\n",
        "\n",
        "### Illustration\n",
        "\n",
        "Assume you're convolving this kernel over a grayscale image:\n",
        "\n",
        "Image Patch (5Ã—5 region):\n",
        "\n",
        "\\begin{bmatrix}\n",
        "52 & 55 & 61 & 59 & 79 \\\\\n",
        "62 & 59 & 55 & 104 & 94 \\\\\n",
        "63 & 65 & \\boxed{66} & 113 & 144 \\\\\n",
        "64 & 70 & 70 & 126 & 154 \\\\\n",
        "69 & 73 & 73 & 139 & 158 \\\\\n",
        "\\end{bmatrix}\n",
        "\n",
        "Apply the averaging kernel:\n",
        "\n",
        "$$\n",
        "\\text{New center pixel} = \\frac{1}{25} \\sum_{i=1}^{5} \\sum_{j=1}^{5} I_{ij} \\approx \\frac{1800}{25} = 72\n",
        "$$\n",
        "\n",
        "So, the center pixel (66) is replaced with 72."
      ],
      "metadata": {
        "id": "f_nv3plP8k7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "img = cv.imread('images/dog.png')\n",
        "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
        "\n",
        "kernel = np.ones((7,7),np.float32)/25\n",
        "dst = cv.filter2D(img,-1,kernel)\n",
        "\n",
        "plt.subplot(121),plt.imshow(img),plt.title('Original')\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(122),plt.imshow(dst),plt.title('Averaging')\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VtjE8rYB5Mrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Blurring (Image Smoothing)\n",
        "\n",
        "**Image blurring** is achieved by **convolving the image with a low-pass filter kernel**.  \n",
        "It is useful for **removing noise**. It actually removes **high-frequency content** (e.g., noise, edges) from the image.  \n",
        "So edges are **blurred a little** bit in this operation (though there are also blurring techniques that don't blur the edges).\n",
        "\n",
        "OpenCV provides **four main types** of blurring techniques.\n",
        "\n",
        "---\n",
        "\n",
        "### 1. Averaging\n",
        "\n",
        "This is done by **convolving an image with a normalized box filter**.  \n",
        "It simply takes the **average of all the pixels** under the kernel area and replaces the **central element**.\n",
        "\n",
        "This is done by the function `cv.blur()` or `cv.boxFilter()`.  \n",
        "Check the docs for more details about the kernel.\n",
        "\n",
        "We must specify the **width and height** of the kernel.\n",
        "\n",
        "A **3Ã—3 normalized box filter** looks like this:\n",
        "\n",
        "$$\n",
        "\\frac{1}{9}\n",
        "\\begin{bmatrix}\n",
        "1 & 1 & 1 \\\\\n",
        "1 & 1 & 1 \\\\\n",
        "1 & 1 & 1\n",
        "\\end{bmatrix}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "Vv7RVpRa8n8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "img = cv.imread('images/dog.png')\n",
        "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
        "\n",
        "blur = cv.blur(img,(25,25))\n",
        "\n",
        "plt.subplot(121),plt.imshow(img),plt.title('Original')\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(122),plt.imshow(blur),plt.title('Blurred')\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "I104gqU588Qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Gaussian Blurring\n",
        "\n",
        "In this method, instead of a **box filter**, a **Gaussian kernel** is used. Gaussian kernels smooth the image in a natural, gradual way. This is more effective than just averaging (box blur), because it respects local structure better.\n",
        "\n",
        "\n",
        "It is done with the function `cv.GaussianBlur()`.\n",
        "\n",
        "You must specify:\n",
        "\n",
        "- The **width and height** of the kernel (must be **positive and odd**).\n",
        "- The **standard deviation** in the X and Y directions: `sigmaX` and `sigmaY`.\n",
        "\n",
        "Behavior notes:\n",
        "\n",
        "- If only `sigmaX` is specified, `sigmaY` is taken as the same value.\n",
        "- If both `sigmaX` and `sigmaY` are set to `0`, they are automatically **calculated from the kernel size**.\n",
        "\n",
        "Gaussian blurring is **highly effective** at removing **Gaussian noise** from an image.\n",
        "\n",
        "If you want, you can **create a Gaussian kernel manually** using the function:  \n",
        "`cv.getGaussianKernel()`\n",
        "\n",
        "---\n",
        "\n",
        "The above code (e.g., from averaging blur) can be modified to use Gaussian blurring like so:"
      ],
      "metadata": {
        "id": "HbjIwDAS-PoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "blur = cv.GaussianBlur(img, (25, 25), sigmaX=0)\n",
        "plt.subplot(121),plt.imshow(img),plt.title('Original')\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(122),plt.imshow(blur),plt.title('Blurred')\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "903Eefcp-Uwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Median Blurring\n",
        "\n",
        "In **median blurring**, the function `cv.medianBlur()` takes the **median** of all the pixels under the kernel area,  \n",
        "and the **central element** is replaced with this **median value**.\n",
        "\n",
        "This method is **highly effective** against **salt-and-pepper noise** in an image.\n",
        "\n",
        "#### Key differences:\n",
        "\n",
        "- In other filters (e.g., average, Gaussian), the central element is a **newly computed value**, possibly one not present in the image.\n",
        "- In **median blurring**, the central element is always replaced by an **existing pixel value** from the neighborhood.\n",
        "- This makes it especially good at **preserving edges** while reducing impulse noise.\n",
        "\n",
        "> ðŸ”¸ The kernel size must be a **positive odd integer** (e.g., 3, 5, 7).\n",
        "\n",
        "---\n",
        "\n",
        "In this demo, we added **50% salt-and-pepper noise** to the original image and applied median blurring.  \n",
        "Check the result:"
      ],
      "metadata": {
        "id": "mIOcGehLAaq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv.imread('images/dog_salt_pepper.png')\n",
        "blur = cv.medianBlur(img,5)\n",
        "plt.subplot(121),plt.imshow(img),plt.title('Original')\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(122),plt.imshow(blur),plt.title('Blurred')\n",
        "plt.xticks([]), plt.yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qYY6zmbD_jpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Gradients\n",
        "\n",
        "Learn to find image gradients, edges etc.\n",
        "\n"
      ],
      "metadata": {
        "id": "kX9GEvFmDP-B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Goal\n",
        "\n",
        "In this chapter, we will learn to:\n",
        "\n",
        "- Find **image gradients**, **edges**, etc.\n",
        "- Use the following OpenCV functions: `cv.Sobel()`, `cv.Scharr()`, `cv.Laplacian()`, etc.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "zv36LX1HELpw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Theory\n",
        "\n",
        "OpenCV provides three types of **gradient filters** (or **high-pass filters**):\n",
        "\n",
        "- Sobel  \n",
        "- Scharr  \n",
        "- Laplacian  \n",
        "\n",
        "We will look at each of them in detail.\n",
        "\n",
        "---\n",
        "\n",
        "### 1. Sobel and Scharr Derivatives\n",
        "\n",
        "- The **Sobel operator** is a combination of **Gaussian smoothing** and **differentiation**, making it more **robust to noise**.\n",
        "- You can specify the direction of the derivative:\n",
        "  - `xorder = 1, yorder = 0` â†’ horizontal gradient  \n",
        "  - `xorder = 0, yorder = 1` â†’ vertical gradient  \n",
        "- You can also specify the **kernel size** using the `ksize` argument.\n",
        "- If `ksize = -1`, a **3Ã—3 Scharr filter** is used, which often gives better results than a 3Ã—3 Sobel filter.\n",
        "\n",
        "ðŸ“„ *See the OpenCV documentation for the exact kernels used.*\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Laplacian Derivatives\n",
        "\n",
        "The **Laplacian** of an image is computed using the following formula:\n",
        "\n",
        "$$\n",
        "\\Delta f = \\frac{\\partial^2 f}{\\partial x^2} + \\frac{\\partial^2 f}{\\partial y^2}\n",
        "$$\n",
        "\n",
        "Each second-order derivative is computed using **Sobel derivatives** internally.\n",
        "\n",
        "If `ksize = 1`, the following kernel is typically used:\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "0 & 1 & 0 \\\\\n",
        "1 & -4 & 1 \\\\\n",
        "0 & 1 & 0\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "This kernel emphasizes areas of **rapid intensity change**, helping in **edge detection**.\n"
      ],
      "metadata": {
        "id": "Qg_CAJUgDVh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "img = cv.imread('images/sudoku.png', cv.IMREAD_GRAYSCALE)\n",
        "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
        "\n",
        "laplacian = cv.Laplacian(img,cv.CV_64F)\n",
        "sobelx = cv.Sobel(img,cv.CV_64F,1,0,ksize=5)\n",
        "sobely = cv.Sobel(img,cv.CV_64F,0,1,ksize=5)\n",
        "\n",
        "plt.subplot(2,2,1),plt.imshow(img,cmap = 'gray')\n",
        "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(2,2,2),plt.imshow(laplacian,cmap = 'gray')\n",
        "plt.title('Laplacian'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(2,2,3),plt.imshow(sobelx,cmap = 'gray')\n",
        "plt.title('Sobel X'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(2,2,4),plt.imshow(sobely,cmap = 'gray')\n",
        "plt.title('Sobel Y'), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Rv1NPEQFEO3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Canny Edge Detection\n",
        "\n",
        "Learn to find edges with Canny Edge Detection\n",
        "\n"
      ],
      "metadata": {
        "id": "DlCBJ0nIEzaD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Goal\n",
        "\n",
        "In this section, we will learn about:\n",
        "\n",
        "- What **Canny edge detection** is\n",
        "- How to use OpenCVâ€™s `cv.Canny()` function\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "2aXMY7riHm8W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is Canny Edge Detection?\n",
        "\n",
        "Canny edge detection is a popular way to **find edges** in an image.  \n",
        "It goes through several steps to make sure the edges it finds are **clear and accurate**.\n",
        "\n",
        "---\n",
        "\n",
        "## Steps in Canny Edge Detection\n",
        "\n",
        "### 1. Noise Reduction\n",
        "\n",
        "First, we remove noise from the image using a **Gaussian blur**.  \n",
        "This makes the image smoother and helps avoid detecting false edges caused by noise.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Find Image Gradients\n",
        "\n",
        "Next, we check how much the image changes in the **X and Y directions** using a filter called **Sobel**.\n",
        "\n",
        "From this, we calculate:\n",
        "\n",
        "- **Gradient magnitude** â€“ how strong the change is  \n",
        "- **Gradient direction** â€“ where the change is happening\n",
        "\n",
        "These help us understand where the edges are.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Non-Maximum Suppression\n",
        "\n",
        "Now we thin the edges by removing weak or unnecessary pixels.\n",
        "\n",
        "For each pixel:\n",
        "\n",
        "- We check if it is the **strongest** compared to its neighbors **in the direction of the edge**\n",
        "- If it is not the strongest, we remove it (set to 0)\n",
        "\n",
        "This leaves us with **thin, clean edges**.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. Hysteresis Thresholding\n",
        "\n",
        "Finally, we decide which edges to **keep** and which to **remove**, using two thresholds:\n",
        "\n",
        "- If the pixel value is **above the high threshold**, we **keep it** â€“ itâ€™s a strong edge\n",
        "- If itâ€™s **below the low threshold**, we **remove it**\n",
        "- If itâ€™s **between**, we keep it **only if itâ€™s connected** to a strong edge\n",
        "\n",
        "This step helps get rid of small false edges and keeps only the important ones.\n",
        "\n",
        "---\n",
        "\n",
        "## Final Result\n",
        "\n",
        "After all the steps, we get an image with **clean, clear edges**.\n",
        "\n",
        "---\n",
        "\n",
        "## Using `cv.Canny()` in OpenCV\n",
        "\n",
        "OpenCV provides a function that does all the steps for you:\n"
      ],
      "metadata": {
        "id": "qUaA1ZjyE4cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "img = cv.imread('images/messi.png', cv.IMREAD_GRAYSCALE)\n",
        "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
        "edges = cv.Canny(img,100,200)\n",
        "\n",
        "plt.subplot(121),plt.imshow(img,cmap = 'gray')\n",
        "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(122),plt.imshow(edges,cmap = 'gray')\n",
        "plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xkDHEnqZHwxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Contours\n",
        "\n",
        "Learn to find and draw Contours\n",
        "\n"
      ],
      "metadata": {
        "id": "1_hisD29MAtD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Goal\n",
        "\n",
        "- Understand what **contours** are  \n",
        "- Learn how to **find** and **draw** contours using OpenCV  \n",
        "- Use functions like: `cv.findContours()`, `cv.drawContours()`\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "WZfLU82cMaJA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What Are Contours?\n",
        "\n",
        "**Contours** are simply curves that connect **continuous points** along the boundary of objects that have the **same color or intensity**.\n",
        "\n",
        "They are useful for:\n",
        "\n",
        "- **Shape analysis**\n",
        "- **Object detection**\n",
        "- **Object recognition**\n",
        "\n",
        "---\n",
        "\n",
        "## Tips for Finding Contours\n",
        "\n",
        "- For better results, use **binary images** (black and white).\n",
        "- Apply **thresholding** or **Canny edge detection** before finding contours.\n",
        "- Since OpenCV 3.2, `cv.findContours()` does **not modify** the original image.\n",
        "- In OpenCV, finding contours means finding **white objects** on a **black background**.\n",
        "  - So make sure your object is **white** and the background is **black**.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "q3zStg9WMuOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "\n",
        "img = cv.imread('images/contours_test.png')\n",
        "assert im is not None, \"file could not be read, check with os.path.exists()\"\n",
        "imgray = cv.cvtColor(im, cv.COLOR_BGR2GRAY)\n",
        "ret, thresh = cv.threshold(imgray, 127, 255, 0)\n",
        "contours, hierarchy = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)"
      ],
      "metadata": {
        "id": "KoDqJAcLM3me"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "See, there are **three arguments** in the `cv.findContours()` function:\n",
        "\n",
        "1. **Source image** â€“ usually a binary image.\n",
        "2. **Contour retrieval mode** â€“ tells how to retrieve contours (e.g. `cv.RETR_TREE`, `cv.RETR_EXTERNAL`, etc.).\n",
        "3. **Contour approximation method** â€“ defines how to approximate the contour shape (e.g. `cv.CHAIN_APPROX_SIMPLE`, `cv.CHAIN_APPROX_NONE`).\n",
        "\n",
        "The function returns:\n",
        "\n",
        "- `contours`: A **Python list** of all the contours found in the image.\n",
        "- `hierarchy`: Information about the **image topology** (parent-child relationship between contours).\n",
        "\n",
        "Each individual contour is a **NumPy array** of `(x, y)` coordinates of the **boundary points** of the object.\n"
      ],
      "metadata": {
        "id": "ntwud3nGNBKH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to draw the contours?\n",
        "\n",
        "To **draw the contours**, the `cv.drawContours()` function is used.  \n",
        "It can also be used to draw any shape, as long as you have its **boundary points**.\n",
        "\n",
        "### Parameters:\n",
        "\n",
        "1. **First argument** â€“ the **source image**\n",
        "2. **Second argument** â€“ the **contours**, passed as a **Python list**\n",
        "3. **Third argument** â€“ the **index** of the contour to draw  \n",
        "   - To draw **all contours**, pass `-1`\n",
        "4. **Remaining arguments** â€“ define the **color**, **thickness**, and other drawing options\n",
        "\n",
        "---\n",
        "\n",
        "This function is very flexible and useful for visualizing the detected shapes and object boundaries.\n"
      ],
      "metadata": {
        "id": "hP0rsqauNJA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To draw all the contours in an image:\n",
        "\n",
        "cv.drawContours(img, contours, -1, (0,255,0), 3)"
      ],
      "metadata": {
        "id": "8rhTc_vPNt3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing and Detecting Multiple Contours with OpenCV\n"
      ],
      "metadata": {
        "id": "tKo-ndxUQp5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the image\n",
        "image = cv2.imread('images/contours_test2.png')\n",
        "\n",
        "# Convert to grayscale\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Apply Canny edge detection\n",
        "edges = cv2.Canny(gray, 50, 150)\n",
        "\n",
        "# Plot grayscale and edges side-by-side\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(gray, cmap='gray')\n",
        "plt.title('Grayscale Image')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(edges, cmap='gray')\n",
        "plt.title('Canny Edges')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Find contours\n",
        "contours, hierarchy = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# Draw all contours\n",
        "output = image.copy()\n",
        "cv2.drawContours(output, contours, -1, (0, 255, 0), 2)\n",
        "\n",
        "# Display using matplotlib\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(cv2.cvtColor(output, cv2.COLOR_BGR2RGB))\n",
        "plt.title(\"All Contours Detected\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "OtKSjOSlPw7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Template Matching\n",
        "\n",
        "Learn to search for an object in an image using Template Matching\n",
        "\n"
      ],
      "metadata": {
        "id": "yAg_5fp4Q0sl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Goals\n",
        "\n",
        "In this section, you will learn:\n",
        "\n",
        "- How to **find objects in an image** using **Template Matching**\n",
        "- How to use `cv.matchTemplate()` and `cv.minMaxLoc()` in OpenCV\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "hXcKSoAPREU1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is Template Matching?\n",
        "\n",
        "**Template Matching** is a method to **find a small image (template)** inside a **larger image**.\n",
        "\n",
        "OpenCV provides the function `cv.matchTemplate()` for this.\n",
        "\n",
        "---\n",
        "\n",
        "### How it works:\n",
        "\n",
        "- The **template image** is slid across the **input image**, like a sliding window.\n",
        "- At each position, it compares how similar the template is to that part of the image.\n",
        "- It produces a **grayscale result image**:\n",
        "  - Each pixel shows how well that area of the image matches the template.\n",
        "  - Brighter areas mean better matches (depending on method used).\n",
        "\n",
        "---\n",
        "\n",
        "### Output Size:\n",
        "\n",
        "If the input image is size `(W Ã— H)`  \n",
        "and the template is size `(w Ã— h)`,  \n",
        "then the output will be size:  \n",
        "`(W - w + 1, H - h + 1)`\n",
        "\n",
        "---\n",
        "\n",
        "### Locating the Best Match:\n",
        "\n",
        "Once you have the result image:\n",
        "\n",
        "- Use `cv.minMaxLoc()` to find the **best match location**\n",
        "  - It gives the **minimum and maximum values and their positions**\n",
        "- Use the location as the **top-left corner** of the detected region\n",
        "- Draw a rectangle with the same size as the template at that spot\n",
        "\n",
        "---\n",
        "\n",
        "This is how you detect where the template appears in the larger image!"
      ],
      "metadata": {
        "id": "7Fo2FSJFRTpU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Template Matching in OpenCV\n",
        "Here, as an example, we will search for Messi's face in his photo.\n",
        "\n",
        "We will try all the comparison methods listed below:\n",
        "\n",
        "| Method             | Description                                                 | Best Match Location |\n",
        "| ------------------ | ----------------------------------------------------------- | ------------------- |\n",
        "| `TM_SQDIFF`        | Sum of squared differences between template and image patch | **Minimum value**   |\n",
        "| `TM_SQDIFF_NORMED` | Same as above, but normalized                               | **Minimum value**   |\n",
        "| `TM_CCORR`         | Cross-correlation between template and image patch          | **Maximum value**   |\n",
        "| `TM_CCORR_NORMED`  | Same as above, but normalized                               | **Maximum value**   |\n",
        "| `TM_CCOEFF`        | Correlation coefficient (compares mean-centered patterns)   | **Maximum value**   |\n",
        "| `TM_CCOEFF_NORMED` | Same as above, but normalized (values between -1 and 1)     | **Maximum value**   |\n",
        "\n",
        "\n",
        "so that we can see how their results look like:"
      ],
      "metadata": {
        "id": "heg55PiCRl2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "img = cv.imread('images/messi.png', cv.IMREAD_GRAYSCALE)\n",
        "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
        "img2 = img.copy()\n",
        "template = cv.imread('images/template.png', cv.IMREAD_GRAYSCALE)\n",
        "assert template is not None, \"file could not be read, check with os.path.exists()\"\n",
        "w, h = template.shape[::-1]\n",
        "\n",
        "# All the 6 methods for comparison in a list\n",
        "methods = ['TM_CCOEFF', 'TM_CCOEFF_NORMED', 'TM_CCORR',\n",
        "            'TM_CCORR_NORMED', 'TM_SQDIFF', 'TM_SQDIFF_NORMED']\n",
        "\n",
        "for meth in methods:\n",
        "    img = img2.copy()\n",
        "    method = getattr(cv, meth)\n",
        "\n",
        "    # Apply template Matching\n",
        "    res = cv.matchTemplate(img,template,method)\n",
        "    min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\n",
        "\n",
        "    # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
        "    if method in [cv.TM_SQDIFF, cv.TM_SQDIFF_NORMED]:\n",
        "        top_left = min_loc\n",
        "    else:\n",
        "        top_left = max_loc\n",
        "    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
        "\n",
        "    cv.rectangle(img,top_left, bottom_right, 255, 2)\n",
        "\n",
        "    plt.subplot(121),plt.imshow(res,cmap = 'gray')\n",
        "    plt.title('Matching Result'), plt.xticks([]), plt.yticks([])\n",
        "    plt.subplot(122),plt.imshow(img,cmap = 'gray')\n",
        "    plt.title('Detected Point'), plt.xticks([]), plt.yticks([])\n",
        "    plt.suptitle(meth)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "pMQjWA19RU_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Segmentation with Watershed Algorithm\n",
        "\n",
        "Learn to segment images with watershed segmentation"
      ],
      "metadata": {
        "id": "fqMQvgaoSb3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Goal\n",
        "\n",
        "In this chapter, you will learn:\n",
        "\n",
        "- How to use **marker-based image segmentation** using the **Watershed algorithm**\n",
        "- How to apply `cv.watershed()` in OpenCV\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "eRcaMo19WWCB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is the Watershed Algorithm?\n",
        "\n",
        "Think of a **grayscale image** as a **3D landscape**:\n",
        "\n",
        "- **Bright areas** (high intensity) are like **hills or peaks**\n",
        "- **Dark areas** (low intensity) are like **valleys**\n",
        "\n",
        "The idea is to \"flood\" the valleys with **water from different sources (labels)**.  \n",
        "As the water rises, if two labeled regions are about to merge, a **barrier** is built between them.\n",
        "\n",
        "Once everything is filled, these barriers form the **boundaries between regions** â€” this is the **segmentation result**.\n",
        "\n",
        "---\n",
        "\n",
        "## Problem with Basic Watershed\n",
        "\n",
        "If we apply this blindly, we often get **too many small regions** (over-segmentation), especially due to **noise**.\n",
        "\n",
        "---\n",
        "\n",
        "## Marker-Based Watershed (OpenCV)\n",
        "\n",
        "OpenCV uses an improved version called **marker-based watershed**, which gives better results.\n",
        "\n",
        "### How it works:\n",
        "\n",
        "1. **You provide markers** to guide the segmentation.\n",
        "   - **Foreground** (sure object) â†’ label with **1**\n",
        "   - **Background** (sure non-object) â†’ label with **2**\n",
        "   - **Unknown regions** (not clear whether it belongs to the foreground or the background) â†’ label with **0**\n",
        "\n",
        "2. These markers act like **seeds**.\n",
        "\n",
        "3. When you call `cv.watershed()`:\n",
        "   - It fills the regions based on your markers.\n",
        "   - The **boundaries** between objects are marked with **-1** in the result.\n",
        "\n",
        "---\n",
        "\n",
        "This is a powerful technique for **separating overlapping objects** or **segmenting complex regions** interactively."
      ],
      "metadata": {
        "id": "9ZWKhN7wW1E0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code\n",
        "\n",
        "Below we will see an example on how to use the Distance Transform along with watershed to segment mutually touching objects.\n",
        "\n",
        "Consider the coins image below, the coins are touching each other. Even if you threshold it, it will be touching each other."
      ],
      "metadata": {
        "id": "8TqY2JHxW5su"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start with finding an approximate estimate of the coins. For that, we can use the Otsu's binarization.\n",
        "\n"
      ],
      "metadata": {
        "id": "jm3pIhjbX_Zn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def show(title, image, cmap='gray'):\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    plt.imshow(image, cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Load the image\n",
        "img = cv.imread('images/coins.png')\n",
        "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
        "\n",
        "# Original Image\n",
        "show(\"Original Image\", cv.cvtColor(img, cv.COLOR_BGR2RGB), cmap=None)\n",
        "\n",
        "# Convert to Grayscale\n",
        "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "show(\"Grayscale\", gray)\n",
        "\n",
        "# Thresholding (Otsu's + Inverse Binary)\n",
        "ret, thresh = cv.threshold(gray, 0, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)\n",
        "show(\"Thresholded (Otsu + Binary Inv)\", thresh)\n",
        "\n",
        "# Noise Removal (Morphological Opening)\n",
        "kernel = np.ones((3, 3), np.uint8)\n",
        "opening = cv.morphologyEx(thresh, cv.MORPH_OPEN, kernel, iterations=2)\n",
        "show(\"After Morphological Opening\", opening)\n",
        "\n",
        "# Sure Background (Dilation)\n",
        "sure_bg = cv.dilate(opening, kernel, iterations=3)\n",
        "show(\"Sure Background\", sure_bg)\n",
        "\n",
        "# Sure Foreground (Distance Transform + Threshold)\n",
        "dist_transform = cv.distanceTransform(opening, cv.DIST_L2, 5)\n",
        "show(\"Distance Transform\", dist_transform)\n",
        "ret, sure_fg = cv.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
        "show(\"Sure Foreground\", sure_fg)\n",
        "\n",
        "# Unknown Region\n",
        "sure_fg = np.uint8(sure_fg)\n",
        "unknown = cv.subtract(sure_bg, sure_fg)\n",
        "show(\"Unknown Region\", unknown)\n",
        "\n",
        "# Marker Labelling\n",
        "ret, markers = cv.connectedComponents(sure_fg)\n",
        "\n",
        "# Increment marker labels so background is not 0 but 1\n",
        "markers = markers + 1\n",
        "\n",
        "# Mark unknown regions as 0\n",
        "markers[unknown == 255] = 0\n",
        "\n",
        "# Apply Watershed\n",
        "markers = cv.watershed(img, markers)\n",
        "\n",
        "show(\"Segmented Image\", markers)\n",
        "\n",
        "# Mark boundaries in red on original image\n",
        "segmented_img = img.copy()\n",
        "segmented_img[markers == -1] = [255, 0, 0]  # boundary marked in red\n",
        "\n",
        "# Display final segmented image\n",
        "show(\"Final Segmented Image (Watershed Boundaries)\", cv.cvtColor(segmented_img, cv.COLOR_BGR2RGB), cmap=None)\n"
      ],
      "metadata": {
        "id": "gdkWLwv6W_Dv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}